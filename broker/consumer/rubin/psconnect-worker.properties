# Kafka connect worker configuration

bootstrap.servers=alert-stream-int.lsst.cloud:9094
plugin.path=/usr/local/share/kafka/plugins
offset.storage.file.filename=/tmp/connect.offsets

# use the schema to convert values
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.schema.registry.url=https://alert-schemas-int.lsst.cloud
value.converter.enhanced.avro.schema.support=true
# Rubin messages don't use the key
# # ByteArrayConverter provides a “pass-through” option that does no conversion
# key.converter=org.apache.kafka.connect.converters.ByteArrayConverter

# workers need to use SASL
sasl.mechanism=SCRAM-SHA-512
sasl.kerberos.service.name=kafka
security.protocol=SASL_SSL
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
   username="pittgoogle-idfint"\
   password="KAFKA_PASSWORD";

# settings with `consumer` prefixes are passed through to the Kafka consumer
consumer.auto.offset.reset=earliest
consumer.sasl.mechanism=SCRAM-SHA-512
consumer.sasl.kerberos.service.name=kafka
consumer.security.protocol=SASL_SSL
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
   username="pittgoogle-idfint"\
   password="KAFKA_PASSWORD";
