# Kafka connect worker configuration
# See: https://docs.confluent.io/platform/current/connect/references/allconfigs.html

bootstrap.servers=alert-stream-int.lsst.cloud:9094
plugin.path=/usr/local/share/kafka/plugins
offset.storage.file.filename=/tmp/connect.offsets

# Rubin messages don't use the key, but a key converter needs to be set here.
# ByteArrayConverter provides a “pass-through” option that does no conversion.
key.converter=org.apache.kafka.connect.converters.ByteArrayConverter

# Kafka Connect can use the Confluent Schema Registry.
# But schemas are stored under subjects and Kafka Connect is picky about how those
# subjects are named. See
# https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#subject-name-strategy
# Rubin has set the schema subject name to “alert-packet”, which does not conform
# to any of the name strategies that Kafka Connect uses.
# I (Troy Raen) did not find a workaround for this issue.
# Instead, I passed the alert bytes straight through into Pub/Sub and deserialized
# them after pulling the messages from Pub/Sub.
# value.converter=io.confluent.connect.avro.AvroConverter
# value.converter.schema.registry.url=https://alert-schemas-int.lsst.cloud
# value.converter.enhanced.avro.schema.support=true
# value.subject.name.strategy=io.confluent.kafka.serializers.subject.TopicNameStrategy
value.converter=org.apache.kafka.connect.converters.ByteArrayConverter

# workers need to use SASL
sasl.mechanism=SCRAM-SHA-512
sasl.kerberos.service.name=kafka
security.protocol=SASL_SSL
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
   username="pittgoogle-idfint"\
   password="KAFKA_PASSWORD";

# settings with `consumer` prefixes are passed through to the Kafka consumer
# consumer.group.id must begin with our username: pittgoogle-idfint
consumer.group.id=pittgoogle-idfint-kafka-pubsub-connector
consumer.auto.offset.reset=earliest
consumer.sasl.mechanism=SCRAM-SHA-512
consumer.sasl.kerberos.service.name=kafka
consumer.security.protocol=SASL_SSL
consumer.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
   username="pittgoogle-idfint"\
   password="KAFKA_PASSWORD";
