#! /bin/bash

PROJECT_ID=$1
# PROJECT_ID=$GOOGLE_CLOUD_PROJECT
testid=$2
beamdir=$3
survey=$4

# sources and sinks
BQ_dataset="${survey}_alerts"
source_PS_alerts="projects/${PROJECT_ID}/topics/${survey}-alerts"
sink_BQ_alerts="${BQ_dataset}.alerts"
sink_BQ_diasource="${BQ_dataset}.DIASource"
sink_BQ_salt2="${BQ_dataset}.salt2"
sink_CS_salt2="${PROJECT_ID}-${survey}-sncosmo"
sink_PS_pure="projects/${PROJECT_ID}/topics/${survey}-alerts_pure"
sink_PS_exgalTrans="projects/${PROJECT_ID}/topics/${survey}-exgalac_trans"
sink_PS_salt2="projects/${PROJECT_ID}/topics/${survey}-salt2"
if [ "$testid" != "False" ]; then
    source_PS_alerts="${source_PS_alerts}-${testid}"
    sink_BQ_alerts="${BQ_dataset}_${testid}.alerts"
    sink_BQ_diasource="${BQ_dataset}_${testid}.DIASource"
    sink_BQ_salt2="${BQ_dataset}_${testid}.salt2"
    sink_CS_salt2="${sink_CS_salt2}-${testid}"
    sink_PS_pure="${sink_PS_pure}-${testid}"
    sink_PS_exgalTrans="${sink_PS_exgalTrans}-${testid}"
    sink_PS_salt2="${sink_PS_salt2}-${testid}"
fi

# job-specific configs
dataflow_job_name_bqsink="${survey}-bq-sink"
dataflow_job_name_valadd="${survey}-value-added"
max_num_workers_bqsink=20
max_num_workers_valadd=10
setup_file_bqsink=${beamdir}/bq_sink/setup.py
setup_file_valadd=${beamdir}/value_added/setup.py
if [ "$testid" != "False" ]; then
    dataflow_job_name_bqsink="${dataflow_job_name_bqsink}-${testid}"
    dataflow_job_name_valadd="${dataflow_job_name_valadd}-${testid}"
fi

# generic job configs
region=us-central1
runner=DataflowRunner
beam_bucket="${PROJECT_ID}-${survey}-dataflow"
if [ "$testid" != "False" ]; then
    beam_bucket="${beam_bucket}-${testid}"
fi
staging_location=gs://${beam_bucket}/staging
temp_location=gs://${beam_bucket}/temp

# Salt2 configs
salt2_SNthresh=5.
salt2_minNdetections=5
